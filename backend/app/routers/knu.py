# app/routers/knu.py
# app/routers/knu.py
import json
from typing import List, Optional, Set, Dict, Any

from fastapi import APIRouter, Depends, Query, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete, or_, desc
from sqlalchemy.orm import selectinload # [ì¶”ê°€] "selectinload" is not defined ì—ëŸ¬ í•´ê²°
from app.database.database import get_db
from app.database.models import Notice, Device, Scrap, Keyword
from app.schemas import (
    NoticeListResponse, 
    NoticeDetailResponse, 
    DeviceRegisterRequest, 
    ScrapRequest,
    KeywordSubscriptionRequest
)
from app.services import knu_notice_service
from app.services.scraper import scrape_notice_content
from app.core.logger import get_logger
from app.utils.security import ensure_allowed_url # [ì¶”ê°€] SSRF ë°©ì§€ìš© ë³´ì•ˆ í•¨ìˆ˜
from app.core.config import NOTICE_CONFIGS
router = APIRouter()
logger = get_logger()

@router.get("/notices", response_model=List[NoticeListResponse])
async def read_notices(
    category: str = "all",
    q: Optional[str] = Query(None, description="ê²€ìƒ‰ì–´"),
    page: int = 1,
    sort_by: str = "date",
    token: Optional[str] = Query(None, description="ìŠ¤í¬ë© í™•ì¸ìš© í† í°"),
    db: AsyncSession = Depends(get_db)
):
    limit = 20
    skip = (page - 1) * limit
    
    results = await knu_notice_service.search_notices(
        db, category, query=q, skip=skip, limit=limit, sort_by=sort_by
    )

    if token:
        # [ë³´ì™„] í† í° ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì‹œ fetchone() ë°©ì‹ë³´ë‹¤ ê¹”ë”í•œ ìŠ¤ì¹¼ë¼ ì¡°íšŒ
        stmt_device = select(Device).filter(Device.token == token)
        res_device = await db.execute(stmt_device)
        device = res_device.scalars().first()
        
        if device:
            stmt_scrap = select(Scrap.notice_id).filter(Scrap.device_id == device.id)
            res_scrap = await db.execute(stmt_scrap)
            my_scrap_ids = set(res_scrap.scalars().all())
            
            for notice in results:
                if notice.id in my_scrap_ids:
                    notice.is_scraped = True

    return results

@router.get("/notice/detail", response_model=NoticeDetailResponse)
async def get_notice_detail(
    url: str, 
    notice_id: Optional[int] = None, 
    token: Optional[str] = Query(None),
    db: AsyncSession = Depends(get_db)
):
    # [1] ë³´ì•ˆ: í—ˆìš©ëœ ë„ë©”ì¸ì¸ì§€ ë¨¼ì € ê²€ì¦ (SSRF ë°©ì§€)
    ensure_allowed_url(url) # [ìˆ˜ì •] ë³´ì•ˆ ê²€ì¦ ì¶”ê°€

    notice_in_db = None
    is_scraped = False

    # [2] DB ë¨¼ì € í™•ì¸
    if notice_id:
        stmt = select(Notice).filter(Notice.id == notice_id)
        result = await db.execute(stmt)
        notice_in_db = result.scalars().first()

    # [3] ìºì‹œ ë¡œì§: DBì— ë³¸ë¬¸ ë‚´ìš©ì´ ì¶©ë¶„íˆ ìˆë‹¤ë©´ í¬ë¡¤ë§ ê±´ë„ˆë›°ê¸°
    # ë³¸ë¬¸ ê¸¸ì´ê°€ 10ì ë¯¸ë§Œì¸ ê²½ìš°ë§Œ ìƒˆë¡œ í¬ë¡¤ë§ (ë°ì´í„° ë³´ê°•)
    if notice_in_db and notice_in_db.content and len(notice_in_db.content) > 10:
        logger.info(f"ğŸ’¾ [Cache Hit] DB ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤: {notice_id}")
        scraped_data: Dict[str, Any] = {
            "title": notice_in_db.title,
            "texts": [notice_in_db.content],
            "images": notice_in_db.images or [],
            "files": notice_in_db.files or [],
            "univ_views": notice_in_db.univ_views,
            "date": notice_in_db.date
        }
    else:
        # DBì— ì—†ê±°ë‚˜ ë³¸ë¬¸ì´ ë¶€ì‹¤í•˜ë©´ ì‹¤ì‹œê°„ í¬ë¡¤ë§ ìˆ˜í–‰
        logger.info(f"ğŸŒ [Scraping] ì›ë¬¸ í˜ì´ì§€ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤: {url}")
        fetched = await scrape_notice_content(url)
        if not fetched:
            raise HTTPException(status_code=404, detail="ì›ë¬¸ í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        scraped_data = fetched

    # [4] ìŠ¤í¬ë© ì—¬ë¶€ í™•ì¸
    if notice_id and token:
        stmt_device = select(Device).filter(Device.token == token)
        res_device = await db.execute(stmt_device)
        device = res_device.scalars().first()
        if device:
            stmt_check = select(Scrap).filter(Scrap.device_id == device.id, Scrap.notice_id == notice_id)
            res_check = await db.execute(stmt_check)
            is_scraped = bool(res_check.scalars().first())

    # [5] DB ì—…ë°ì´íŠ¸ (ë‚´ìš©ì´ ë°”ë€Œì—ˆê±°ë‚˜ ìƒˆë¡œ ìˆ˜ì§‘ëœ ê²½ìš°)
    if notice_in_db and not (notice_in_db.content and len(notice_in_db.content) > 10):
        notice_in_db.content = "\n\n".join(scraped_data.get("texts", []))
        try:
            await db.commit()
        except Exception:
            await db.rollback()

    univ_views = scraped_data.get("univ_views", 0)
    app_views = notice_in_db.app_views if notice_in_db else 0
    
    return {
        "id": notice_id if notice_id else 0,
        "title": scraped_data["title"],
        "link": url,
        "date": scraped_data["date"],
        "category": notice_in_db.category if notice_in_db else "unknown",
        "author": notice_in_db.author if notice_in_db else None,
        "content": "\n\n".join(scraped_data.get("texts", [])),
        "images": scraped_data.get("images", []),
        "files": scraped_data.get("files", []),
        "univ_views": univ_views,
        "app_views": app_views,
        "views": (univ_views or 0) + (app_views or 0),
        "crawled_at": notice_in_db.crawled_at if notice_in_db else None,
        "is_scraped": is_scraped,
        "summary": notice_in_db.summary if notice_in_db else None
    }
@router.post("/notice/{notice_id}/view")
async def increment_view_count(notice_id: int, db: AsyncSession = Depends(get_db)):
    stmt = select(Notice).filter(Notice.id == notice_id)
    result = await db.execute(stmt)
    notice = result.scalars().first()
    
    if not notice:
        raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        # [Fix] Optional[int]ì™€ int ë§ì…ˆ ì²˜ë¦¬ (models.py íŒíŠ¸ ë•ë¶„ì— ì•ˆì „)
        current_views = notice.app_views or 0
        notice.app_views = current_views + 1
        await db.commit()
        await db.refresh(notice)
        
        return {
            "success": True,
            "app_views": notice.app_views
        }
    except Exception as e:
        await db.rollback()
        logger.error(f"ì¡°íšŒìˆ˜ ì¦ê°€ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail="ì¡°íšŒìˆ˜ ì¦ê°€ ì‹¤íŒ¨")

@router.post("/notice/{notice_id}/summary")
async def create_notice_summary(notice_id: int, db: AsyncSession = Depends(get_db)):
    try:
        summary = await knu_notice_service.get_or_create_summary(db, notice_id)
        return {"summary": summary}
    except ValueError:
        raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"Summary Error: {e}")
        raise HTTPException(status_code=500, detail="ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜")
        
@router.post("/device/register")
async def register_device(request: DeviceRegisterRequest, db: AsyncSession = Depends(get_db)):
    stmt = select(Device).filter(Device.token == request.token)
    result = await db.execute(stmt)
    existing = result.scalars().first()
    
    # [Note] í‚¤ì›Œë“œ ë¡œì§ì€ ë³„ë„ í…Œì´ë¸”ë¡œ ë¶„ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” í† í° ë“±ë¡/ê°±ì‹ ë§Œ ì§‘ì¤‘
    if not existing:
        new_device = Device(token=request.token)
        db.add(new_device)
        logger.info(f"âœ¨ ê¸°ê¸° ë“±ë¡: {request.token[:8]}...")
    else:
        logger.info(f"ğŸ”„ ê¸°ê¸° í™•ì¸: {request.token[:8]}...")
    
    try:
        await db.commit()
        return {"message": "success"}
    except:
        await db.rollback()
        raise HTTPException(status_code=500, detail="ê¸°ê¸° ë“±ë¡ ì‹¤íŒ¨")

@router.post("/scrap/{notice_id}")
async def toggle_scrap(notice_id: int, request: ScrapRequest, db: AsyncSession = Depends(get_db)):
    res_device = await db.execute(select(Device).filter(Device.token == request.token))
    device = res_device.scalars().first()
    if not device:
        raise HTTPException(status_code=404, detail="ê¸°ê¸° ë“±ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    res_notice = await db.execute(select(Notice).filter(Notice.id == notice_id))
    notice = res_notice.scalars().first()
    if not notice:
        raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

    stmt_scrap = select(Scrap).filter(
        Scrap.device_id == device.id, 
        Scrap.notice_id == notice_id
    )
    res_scrap = await db.execute(stmt_scrap)
    existing_scrap = res_scrap.scalars().first()

    try:
        if existing_scrap:
            await db.delete(existing_scrap)
            await db.commit()
            return {"status": "removed", "message": "ìŠ¤í¬ë© ì·¨ì†Œë¨"}
        else:
            new_scrap = Scrap(device_id=device.id, notice_id=notice_id)
            db.add(new_scrap)
            await db.commit()
            return {"status": "added", "message": "ìŠ¤í¬ë© ì €ì¥ë¨"}
    except Exception as e:
        await db.rollback()
        logger.error(f"ìŠ¤í¬ë© ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail="DB Error")

@router.get("/scraps", response_model=List[NoticeListResponse])
async def get_my_scraps(token: str, db: AsyncSession = Depends(get_db)):
    res_device = await db.execute(select(Device).filter(Device.token == token))
    device = res_device.scalars().first()
    
    if not device:
        return []

    stmt = (
        select(Notice)
        .join(Scrap, Notice.id == Scrap.notice_id)
        .filter(Scrap.device_id == device.id)
        .order_by(Scrap.created_at.desc())
    )
    result = await db.execute(stmt)
    scraped_notices = result.scalars().all()

    for notice in scraped_notices:
        notice.is_scraped = True
        
    return scraped_notices

@router.post("/device/subscriptions")
async def update_device_subscriptions(
    request: KeywordSubscriptionRequest, 
    db: AsyncSession = Depends(get_db)
):
    """
    ì‚¬ìš©ìì˜ ì¹´í…Œê³ ë¦¬ êµ¬ë… ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. (ì´ë¯¸ì§€ UIì˜ 'ì™„ë£Œ' ëŒ€ì‘)
    """
    # 1. ê¸°ê¸° ì¡´ì¬ í™•ì¸
    stmt_device = select(Device).filter(Device.token == request.token).options(selectinload(Device.subscriptions))
    res_device = await db.execute(stmt_device)
    device = res_device.scalars().first()

    if not device:
        # ê¸°ê¸°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        device = Device(token=request.token)
        db.add(device)
        await db.flush() # ID ìƒì„±ì„ ìœ„í•´ flush
    
    # 2. ìš”ì²­ëœ ì¹´í…Œê³ ë¦¬(Keyword) ê°ì²´ë“¤ ê°€ì ¸ì˜¤ê¸°
    if request.categories:
        # DBì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í‚¤ì›Œë“œ ì¡°íšŒ
        stmt_keys = select(Keyword).where(Keyword.word.in_(request.categories))
        res_keys = await db.execute(stmt_keys)
        existing_keywords = res_keys.scalars().all()
        existing_words = {k.word for k in existing_keywords}

        # DBì— ì—†ëŠ” í‚¤ì›Œë“œëŠ” ìƒˆë¡œ ìƒì„±
        new_keywords = [
            Keyword(word=cat) for cat in request.categories if cat not in existing_words
        ]
        if new_keywords:
            db.add_all(new_keywords)
            await db.flush()
            all_keywords = existing_keywords + new_keywords
        else:
            all_keywords = existing_keywords
        
        # 3. ê¸°ê¸°ì˜ êµ¬ë… ë¦¬ìŠ¤íŠ¸ êµì²´ (M:N ê´€ê³„ ì—…ë°ì´íŠ¸)
        device.subscriptions = all_keywords
    else:
        # ì¹´í…Œê³ ë¦¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ëª¨ë“  êµ¬ë… í•´ì œ
        device.subscriptions = []

    try:
        await db.commit()
        logger.info(f"ğŸ”” êµ¬ë… ì—…ë°ì´íŠ¸ ì„±ê³µ: {device.token[:8]}... -> {request.categories}")
        return {"message": "subscriptions updated", "count": len(device.subscriptions)}
    except Exception as e:
        await db.rollback()
        logger.error(f"âŒ êµ¬ë… ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="Subscription sync failed")
    
# [New] ì¹´í…Œê³ ë¦¬ ë§¤í•‘ í…Œì´ë¸” ë°˜í™˜ (í”„ë¡ íŠ¸ UIìš©)
@router.get("/categories")
async def get_categories():
    """notices.json ê¸°ë°˜ìœ¼ë¡œ ì˜ë¬¸ í‚¤ì™€ í•œê¸€ ì´ë¦„ì„ ë§¤í•‘í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return [{"key": k, "name": v["name"]} for k, v in NOTICE_CONFIGS.items()]