# app/routers/knu.py
import json
import traceback
from typing import List, Optional, Set

from fastapi import APIRouter, Depends, Query, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete, or_, desc

from app.database.database import get_db
from app.database.models import Notice, Device, Scrap
from app.schemas import (
    NoticeListResponse, 
    NoticeDetailResponse, 
    DeviceRegisterRequest, 
    ScrapRequest
)
from app.services import knu_notice_service
from app.services.scraper import scrape_notice_content
from app.services.ai_service import generate_summary
from app.core.logger import get_logger

router = APIRouter()
logger = get_logger()

# --------------------------------------------------------------------------
# 1. ê³µì§€ì‚¬í•­ ëª©ë¡ ì¡°íšŒ (Async Refactored)
# --------------------------------------------------------------------------
@router.get("/notices", response_model=List[NoticeListResponse])
async def read_notices(
    category: str = "all",
    q: Optional[str] = Query(None, description="ê²€ìƒ‰ì–´"),
    page: int = 1,
    sort_by: str = "date",
    token: Optional[str] = Query(None, description="ìŠ¤í¬ë© í™•ì¸ìš© í† í°"),
    db: AsyncSession = Depends(get_db)  # Session -> AsyncSession ë³€ê²½
):
    limit = 20
    skip = (page - 1) * limit
    
    # [Fix] ì„œë¹„ìŠ¤ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ await ì¶”ê°€ (knu_notice_serviceê°€ async í•¨ìˆ˜ì„)
    results = await knu_notice_service.search_notices(
        db, category, query=q, skip=skip, limit=limit, sort_by=sort_by
    )

    # ìŠ¤í¬ë© ì—¬ë¶€ ë§ˆí‚¹ (Async ì¿¼ë¦¬ë¡œ ë³€ê²½)
    if token:
        # ê¸°ê¸° ì¡°íšŒ
        stmt_device = select(Device).filter(Device.token == token)
        res_device = await db.execute(stmt_device)
        device = res_device.scalars().first()
        
        if device:
            # ë‚´ ìŠ¤í¬ë© ëª©ë¡ ì¡°íšŒ
            stmt_scrap = select(Scrap.notice_id).filter(Scrap.device_id == device.id)
            res_scrap = await db.execute(stmt_scrap)
            my_scrap_ids = set(res_scrap.scalars().all())
            
            for notice in results:
                if notice.id in my_scrap_ids:
                    notice.is_scraped = True

    return results

# --------------------------------------------------------------------------
# 2. ê³µì§€ì‚¬í•­ ìƒì„¸ ì¡°íšŒ (Async Refactored)
# --------------------------------------------------------------------------
@router.get("/notice/detail", response_model=NoticeDetailResponse)
async def get_notice_detail(
    url: str, 
    notice_id: Optional[int] = None, 
    token: Optional[str] = Query(None),
    db: AsyncSession = Depends(get_db)
):
    notice_in_db = None
    is_scraped = False

    # A. DB ì¡°íšŒ ë° ì¡°íšŒìˆ˜ ì¦ê°€
    if notice_id:
        stmt = select(Notice).filter(Notice.id == notice_id)
        result = await db.execute(stmt)
        notice_in_db = result.scalars().first()

        if notice_in_db:
            try:
                # ì¡°íšŒìˆ˜ 1 ì¦ê°€
                notice_in_db.app_views += 1
                await db.commit() # [Fix] await ì¶”ê°€
            except Exception:
                await db.rollback() # [Fix] await ì¶”ê°€

            # ìŠ¤í¬ë© ì—¬ë¶€ í™•ì¸
            if token:
                stmt_device = select(Device).filter(Device.token == token)
                res_device = await db.execute(stmt_device)
                device = res_device.scalars().first()
                
                if device:
                    stmt_check = select(Scrap).filter(
                        Scrap.device_id == device.id, 
                        Scrap.notice_id == notice_id
                    )
                    res_check = await db.execute(stmt_check)
                    is_scraped = bool(res_check.scalars().first())

    # B. ì‹¤ì‹œê°„ ë‚´ìš© í¬ë¡¤ë§ (ì´ë¯¸ Async í•¨ìˆ˜ì„)
    scraped_data = await scrape_notice_content(url)
    if not scraped_data:
        raise HTTPException(status_code=404, detail="ì›ë¬¸ í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # C. DB ì—…ë°ì´íŠ¸ (Async Commit)
    if notice_in_db:
        new_full_content = "\n\n".join(scraped_data["texts"])
        if notice_in_db.content != new_full_content:
            notice_in_db.content = new_full_content
            try:
                await db.commit()
            except Exception:
                await db.rollback()

    return {
        "id": notice_id if notice_id else 0,
        "title": scraped_data["title"],
        "link": url,
        "date": scraped_data["date"],
        "category": notice_in_db.category if notice_in_db else "unknown",
        "author": notice_in_db.author if notice_in_db else None,
        "content": "\n\n".join(scraped_data["texts"]),
        "images": scraped_data["images"],
        "files": scraped_data["files"],
        "univ_views": scraped_data["univ_views"],
        "app_views": notice_in_db.app_views if notice_in_db else 0,
        "crawled_at": notice_in_db.crawled_at if notice_in_db else None,
        "is_scraped": is_scraped,
        "summary": notice_in_db.summary if notice_in_db else None
    }

# --------------------------------------------------------------------------
# 3. AI ìš”ì•½ ìƒì„± (Async Refactored) - ì—ëŸ¬ ë°œìƒí•˜ë˜ ë¶€ë¶„
# --------------------------------------------------------------------------

@router.post("/notice/{notice_id}/summary")
async def create_notice_summary(notice_id: int, db: AsyncSession = Depends(get_db)):
    try:
        # ì„œë¹„ìŠ¤ ê³„ì¸µìœ¼ë¡œ ë¡œì§ ìœ„ì„
        summary = await knu_notice_service.get_or_create_summary(db, notice_id)
        return {"summary": summary}
    except ValueError:
        raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"Summary Error: {e}")
        raise HTTPException(status_code=500, detail="ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜")
# --------------------------------------------------------------------------
# 4. ê¸°ê¸° ë“±ë¡ ë° ìŠ¤í¬ë© API (Async Refactored)
# --------------------------------------------------------------------------
@router.post("/device/register")
async def register_device(request: DeviceRegisterRequest, db: AsyncSession = Depends(get_db)):
    stmt = select(Device).filter(Device.token == request.token)
    result = await db.execute(stmt)
    existing = result.scalars().first()
    
    if existing:
        existing.keywords = request.keywords
        logger.info(f"ğŸ”„ ê¸°ê¸° ê°±ì‹ : {request.token[:8]}...")
    else:
        new_device = Device(token=request.token, keywords=request.keywords)
        db.add(new_device)
        logger.info(f"âœ¨ ê¸°ê¸° ë“±ë¡: {request.token[:8]}...")
    
    try:
        await db.commit()
        return {"message": "success", "keywords": request.keywords}
    except:
        await db.rollback()
        raise HTTPException(status_code=500, detail="ê¸°ê¸° ë“±ë¡ ì‹¤íŒ¨")

@router.post("/scrap/{notice_id}")
async def toggle_scrap(notice_id: int, request: ScrapRequest, db: AsyncSession = Depends(get_db)):
    # ê¸°ê¸° í™•ì¸
    res_device = await db.execute(select(Device).filter(Device.token == request.token))
    device = res_device.scalars().first()
    if not device:
        raise HTTPException(status_code=404, detail="ê¸°ê¸° ë“±ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # ê³µì§€ í™•ì¸
    res_notice = await db.execute(select(Notice).filter(Notice.id == notice_id))
    notice = res_notice.scalars().first()
    if not notice:
        raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ìŠ¤í¬ë© ì—¬ë¶€ í™•ì¸
    stmt_scrap = select(Scrap).filter(
        Scrap.device_id == device.id, 
        Scrap.notice_id == notice_id
    )
    res_scrap = await db.execute(stmt_scrap)
    existing_scrap = res_scrap.scalars().first()

    try:
        if existing_scrap:
            # ì‚­ì œ ì‹œ delete(...) ëŒ€ì‹  ê°ì²´ë¥¼ db.delete()ë¡œ ë„˜ê¸°ê±°ë‚˜ stmt ì‹¤í–‰
            await db.delete(existing_scrap)
            await db.commit()
            return {"status": "removed", "message": "ìŠ¤í¬ë© ì·¨ì†Œë¨"}
        else:
            new_scrap = Scrap(device_id=device.id, notice_id=notice_id)
            db.add(new_scrap)
            await db.commit()
            return {"status": "added", "message": "ìŠ¤í¬ë© ì €ì¥ë¨"}
    except Exception as e:
        await db.rollback()
        logger.error(f"ìŠ¤í¬ë© ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail="DB Error")

@router.get("/scraps", response_model=List[NoticeListResponse])
async def get_my_scraps(token: str, db: AsyncSession = Depends(get_db)):
    res_device = await db.execute(select(Device).filter(Device.token == token))
    device = res_device.scalars().first()
    
    if not device:
        return []

    # Join ì¿¼ë¦¬ (2.0 Style)
    stmt = (
        select(Notice)
        .join(Scrap, Notice.id == Scrap.notice_id)
        .filter(Scrap.device_id == device.id)
        .order_by(Scrap.created_at.desc())
    )
    result = await db.execute(stmt)
    scraped_notices = result.scalars().all()

    for notice in scraped_notices:
        notice.is_scraped = True
        
    return scraped_notices