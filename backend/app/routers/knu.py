# app/routers/knu.py
import json
from typing import List, Optional, Set

from fastapi import APIRouter, Depends, Query, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete, or_, desc

from app.database.database import get_db
from app.database.models import Notice, Device, Scrap
from app.schemas import (
    NoticeListResponse, 
    NoticeDetailResponse, 
    DeviceRegisterRequest, 
    ScrapRequest
)
from app.services import knu_notice_service
from app.services.scraper import scrape_notice_content
from app.core.logger import get_logger

router = APIRouter()
logger = get_logger()

@router.get("/notices", response_model=List[NoticeListResponse])
async def read_notices(
    category: str = "all",
    q: Optional[str] = Query(None, description="ê²€ìƒ‰ì–´"),
    page: int = 1,
    sort_by: str = "date",
    token: Optional[str] = Query(None, description="ìŠ¤í¬ë© í™•ì¸ìš© í† í°"),
    db: AsyncSession = Depends(get_db)
):
    limit = 20
    skip = (page - 1) * limit
    
    # [Fix] q (Optional[str]) ì „ë‹¬ ì‹œ Pylance í˜¸í™˜ì„± í™•ë³´ (Service í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ìˆ˜ì •ë¨)
    results = await knu_notice_service.search_notices(
        db, category, query=q, skip=skip, limit=limit, sort_by=sort_by
    )

    if token:
        stmt_device = select(Device).filter(Device.token == token)
        res_device = await db.execute(stmt_device)
        device = res_device.scalars().first()
        
        if device:
            stmt_scrap = select(Scrap.notice_id).filter(Scrap.device_id == device.id)
            res_scrap = await db.execute(stmt_scrap)
            my_scrap_ids = set(res_scrap.scalars().all())
            
            for notice in results:
                if notice.id in my_scrap_ids:
                    notice.is_scraped = True

    return results

@router.get("/notice/detail", response_model=NoticeDetailResponse)
async def get_notice_detail(
    url: str, 
    notice_id: Optional[int] = None, 
    token: Optional[str] = Query(None),
    db: AsyncSession = Depends(get_db)
):
    notice_in_db = None
    is_scraped = False

    if notice_id:
        stmt = select(Notice).filter(Notice.id == notice_id)
        result = await db.execute(stmt)
        notice_in_db = result.scalars().first()

        if notice_in_db:
            if token:
                stmt_device = select(Device).filter(Device.token == token)
                res_device = await db.execute(stmt_device)
                device = res_device.scalars().first()
                
                if device:
                    stmt_check = select(Scrap).filter(
                        Scrap.device_id == device.id, 
                        Scrap.notice_id == notice_id
                    )
                    res_check = await db.execute(stmt_check)
                    is_scraped = bool(res_check.scalars().first())

    scraped_data = await scrape_notice_content(url)
    if not scraped_data:
        raise HTTPException(status_code=404, detail="ì›ë¬¸ í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # [Fix] Pylance: notice_in_dbê°€ Noneì´ ì•„ë‹˜ì„ ë³´ì¥í•œ í›„ ì ‘ê·¼
    if notice_in_db:
        new_full_content = "\n\n".join(scraped_data["texts"])
        # models.pyì— íƒ€ì… íŒíŠ¸ë¥¼ ì¶”ê°€í–ˆìœ¼ë¯€ë¡œ ì—ëŸ¬ ì‚¬ë¼ì§
        if notice_in_db.content != new_full_content:
            notice_in_db.content = new_full_content
            try:
                await db.commit()
            except Exception:
                await db.rollback()

    univ_views = scraped_data.get("univ_views", 0)
    app_views = notice_in_db.app_views if notice_in_db else 0
    total_views = (univ_views or 0) + (app_views or 0)
    
    return {
        "id": notice_id if notice_id else 0,
        "title": scraped_data["title"],
        "link": url,
        "date": scraped_data["date"],
        "category": notice_in_db.category if notice_in_db else "unknown",
        "author": notice_in_db.author if notice_in_db else None,
        "content": "\n\n".join(scraped_data["texts"]),
        "images": scraped_data["images"],
        "files": scraped_data["files"],
        "univ_views": univ_views,
        "app_views": app_views,
        "views": total_views,
        "crawled_at": notice_in_db.crawled_at if notice_in_db else None,
        "is_scraped": is_scraped,
        "summary": notice_in_db.summary if notice_in_db else None
    }

@router.post("/notice/{notice_id}/view")
async def increment_view_count(notice_id: int, db: AsyncSession = Depends(get_db)):
    stmt = select(Notice).filter(Notice.id == notice_id)
    result = await db.execute(stmt)
    notice = result.scalars().first()
    
    if not notice:
        raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        # [Fix] Optional[int]ì™€ int ë§ì…ˆ ì²˜ë¦¬ (models.py íŒíŠ¸ ë•ë¶„ì— ì•ˆì „)
        current_views = notice.app_views or 0
        notice.app_views = current_views + 1
        await db.commit()
        await db.refresh(notice)
        
        return {
            "success": True,
            "app_views": notice.app_views
        }
    except Exception as e:
        await db.rollback()
        logger.error(f"ì¡°íšŒìˆ˜ ì¦ê°€ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail="ì¡°íšŒìˆ˜ ì¦ê°€ ì‹¤íŒ¨")

@router.post("/notice/{notice_id}/summary")
async def create_notice_summary(notice_id: int, db: AsyncSession = Depends(get_db)):
    try:
        summary = await knu_notice_service.get_or_create_summary(db, notice_id)
        return {"summary": summary}
    except ValueError:
        raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"Summary Error: {e}")
        raise HTTPException(status_code=500, detail="ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜")
        
@router.post("/device/register")
async def register_device(request: DeviceRegisterRequest, db: AsyncSession = Depends(get_db)):
    stmt = select(Device).filter(Device.token == request.token)
    result = await db.execute(stmt)
    existing = result.scalars().first()
    
    # [Note] í‚¤ì›Œë“œ ë¡œì§ì€ ë³„ë„ í…Œì´ë¸”ë¡œ ë¶„ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” í† í° ë“±ë¡/ê°±ì‹ ë§Œ ì§‘ì¤‘
    if not existing:
        new_device = Device(token=request.token)
        db.add(new_device)
        logger.info(f"âœ¨ ê¸°ê¸° ë“±ë¡: {request.token[:8]}...")
    else:
        logger.info(f"ğŸ”„ ê¸°ê¸° í™•ì¸: {request.token[:8]}...")
    
    try:
        await db.commit()
        return {"message": "success"}
    except:
        await db.rollback()
        raise HTTPException(status_code=500, detail="ê¸°ê¸° ë“±ë¡ ì‹¤íŒ¨")

@router.post("/scrap/{notice_id}")
async def toggle_scrap(notice_id: int, request: ScrapRequest, db: AsyncSession = Depends(get_db)):
    res_device = await db.execute(select(Device).filter(Device.token == request.token))
    device = res_device.scalars().first()
    if not device:
        raise HTTPException(status_code=404, detail="ê¸°ê¸° ë“±ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    res_notice = await db.execute(select(Notice).filter(Notice.id == notice_id))
    notice = res_notice.scalars().first()
    if not notice:
        raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

    stmt_scrap = select(Scrap).filter(
        Scrap.device_id == device.id, 
        Scrap.notice_id == notice_id
    )
    res_scrap = await db.execute(stmt_scrap)
    existing_scrap = res_scrap.scalars().first()

    try:
        if existing_scrap:
            await db.delete(existing_scrap)
            await db.commit()
            return {"status": "removed", "message": "ìŠ¤í¬ë© ì·¨ì†Œë¨"}
        else:
            new_scrap = Scrap(device_id=device.id, notice_id=notice_id)
            db.add(new_scrap)
            await db.commit()
            return {"status": "added", "message": "ìŠ¤í¬ë© ì €ì¥ë¨"}
    except Exception as e:
        await db.rollback()
        logger.error(f"ìŠ¤í¬ë© ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail="DB Error")

@router.get("/scraps", response_model=List[NoticeListResponse])
async def get_my_scraps(token: str, db: AsyncSession = Depends(get_db)):
    res_device = await db.execute(select(Device).filter(Device.token == token))
    device = res_device.scalars().first()
    
    if not device:
        return []

    stmt = (
        select(Notice)
        .join(Scrap, Notice.id == Scrap.notice_id)
        .filter(Scrap.device_id == device.id)
        .order_by(Scrap.created_at.desc())
    )
    result = await db.execute(stmt)
    scraped_notices = result.scalars().all()

    for notice in scraped_notices:
        notice.is_scraped = True
        
    return scraped_notices