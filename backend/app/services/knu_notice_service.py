import json
import html as html_lib
import asyncio
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from sqlalchemy.orm import Session
from sqlalchemy import or_

from app.core.config import get_urls 
from app.core.http import fetch_html
from app.database.models import Notice

async def crawl_and_sync_notices(db: Session, category: str = "univ"):
    print(f"ðŸ”„ [{category}] ë™ê¸°í™” ìž‘ì—… ì‹œìž‘...")
    
    list_url, info_url, default_seq = get_urls(category)
    
    try:
        html_text = await fetch_html(list_url, params={"searchMenuSeq": default_seq})
        soup = BeautifulSoup(html_text, "html.parser")
    except Exception as e:
        print(f"âŒ [{category}] ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
        return

    new_count = 0
    # [NEW] ì´ë²ˆ í¬ë¡¤ë§ í„´ì—ì„œ ì²˜ë¦¬í•œ ë§í¬ë¥¼ ê¸°ì–µí•˜ëŠ” ì§‘í•©
    processed_links = set() 
    
    for a in soup.select("a.detailLink[data-params]"):
        try:
            # 1. íŒŒì‹± ë¡œì§
            title = a.get_text(" ", strip=True) or a.get("title", "").strip()
            raw = html_lib.unescape(a.get("data-params", "")).strip()

            try:
                params = json.loads(raw)
            except Exception:
                try:
                    params = json.loads(raw.replace("'", '"'))
                except Exception:
                    continue

            enc_menu_seq = params.get("encMenuSeq")
            enc_menu_board_seq = params.get("encMenuBoardSeq")
            scrt_wrt_yn = params.get("scrtWrtYn", False)

            if not (enc_menu_seq and enc_menu_board_seq):
                continue

            # 2. ë§í¬ ìƒì„±
            detail_url = (
                f"{info_url}"
                f"?scrtWrtYn={'true' if scrt_wrt_yn else 'false'}"
                f"&encMenuSeq={enc_menu_seq}"
                f"&encMenuBoardSeq={enc_menu_board_seq}"
            )

            # -------------------------------------------------------
            # [FIX] ì´ì¤‘ ë°©ì–´ë§‰ ê°€ë™!
            # -------------------------------------------------------
            
            # ë°©ì–´ë§‰ 1ë‹¨ê³„: ë°©ê¸ˆ ë‚´ê°€ ì²˜ë¦¬í•œ ë§í¬ì¸ê°€? (ìƒë‹¨ ê³ ì • ê³µì§€ ì¤‘ë³µ ë°©ì§€)
            if detail_url in processed_links:
                continue
            processed_links.add(detail_url)

            # ë°©ì–´ë§‰ 2ë‹¨ê³„: ì˜›ë‚ ì— DBì— ì €ìž¥í•œ ë§í¬ì¸ê°€?
            if db.query(Notice).filter(Notice.link == detail_url).first():
                continue

            # -------------------------------------------------------

            # 3. ìƒì„¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            detail_content = await get_notice_content_only(detail_url)

            # 4. ì €ìž¥ ì¤€ë¹„
            new_notice = Notice(
                title=title,
                link=detail_url,
                content=detail_content,
                category=category,
            )
            db.add(new_notice)
            new_count += 1
            
            await asyncio.sleep(0.1) 

        except Exception as e:
            print(f"âš ï¸ ì•„ì´í…œ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
            continue

    try:
        db.commit() # í•œë°©ì— ì €ìž¥
        if new_count > 0:
            print(f"âœ… [{category}] {new_count}ê°œ ì‹ ê·œ ê³µì§€ ì €ìž¥ ì™„ë£Œ!")
        else:
            print(f"ðŸ’¤ [{category}] ìƒˆë¡œìš´ ê³µì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        db.rollback() # ì—ëŸ¬ë‚˜ë©´ ë˜ëŒë¦¬ê¸°
        print(f"ðŸ”¥ DB ì €ìž¥ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ (ë¡¤ë°±ë¨): {e}")


async def get_notice_content_only(detail_url: str) -> str:
    try:
        html = await fetch_html(detail_url)
        soup = BeautifulSoup(html, "html.parser")
        content_el = soup.select_one(".view_cont, .board_view, .contents, #contents, .content")
        return content_el.get_text("\n", strip=True) if content_el else ""
    except Exception:
        return ""

def search_notices_from_db(db: Session, category: str, query: str = None, skip: int = 0, limit: int = 20):
    sql = db.query(Notice)
    if category != "all":
        sql = sql.filter(Notice.category == category)
    if query:
        search_filter = f"%{query}%"
        sql = sql.filter(
            or_(Notice.title.like(search_filter), Notice.content.like(search_filter))
        )
    return sql.order_by(Notice.id.desc()).offset(skip).limit(limit).all()